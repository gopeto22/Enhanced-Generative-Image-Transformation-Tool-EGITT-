Enhanced Generative Image Transformation Tool (EGITT)

OVERVIEW:
The Enhanced Generative Image Transformation Tool (EGITT) is a project focused on addressing the limitations of current generative models for image transformation and generation. It employs advanced variations of Generative Adversarial Networks (GANs) and real-time style transfer techniques to improve the quality, style fidelity, and resolution of AI-generated images. The project combines systematic experimentation with a comprehensive evaluation framework.

This repository includes the code and resources for implementing various GAN architectures and a real-time style transfer model.

FEATURES:
GAN Implementations:
Standard GAN
Wasserstein GAN (WGAN) with Weight Clipping
Conditional Wasserstein GAN
Wasserstein GAN with Gradient Penalty (WGAN-GP)
Style Transfer:
Real-time style transfer model that applies the style of one image to the content of another in real-time.
Evaluation Framework:
Quantitative metrics such as Fr√©chet Inception Distance (FID) and Inception Score (IS).
Qualitative evaluations including user studies and peer feedback on style-transferred images.
Installation

PREREQUISITES:
Before you begin, ensure you have the following installed:

Python 3.x
PyTorch
NumPy
OpenCV (for image processing)
Matplotlib (for visualization)
Additional dependencies as specified in requirements.txt
To install the dependencies, run:
```
pip install -r requirements.txt
```
USAGE:
1. Running GAN Models
Each GAN model has its own script. To run the Standard GAN, use:
```
python standard_GAN.py --dataset CelebA --epochs 100
```
For Wasserstein GAN with Gradient Penalty (WGAN-GP):
```
python WGAN_construction.py --dataset CelebA --epochs 100
```
To run Wasserstein GAN with FID evaluation:
```
python WGAN_FID.py --dataset CelebA --epochs 100
```
To run Conditional WGAN:
```
python ConditionalWGAN_attempt.py --dataset CelebA --epochs 100
```
2. Real-Time Style Transfer
To apply real-time style transfer on an image:
```
python Image_Transformer.py --content-image path/to/content.jpg --style-image path/to/style.jpg --output path/to/output.jpg
```
3. Image-to-Image Transformation
To run the image-to-image transformation model:
```
python I2I_transformation.py --input path/to/input.jpg --output path/to/output.jpg
```

DATASETS
CelebA: A large-scale dataset of celebrity faces, used for training GAN models.
COCO-2017: A dataset commonly used for object detection and segmentation tasks, used in the style transfer model.
Ensure you download and place the datasets in the appropriate folders before running the models.

RESULTS:
Sample Results:
Standard GAN: Generated realistic celebrity faces using the CelebA dataset.
WGAN & WGAN-GP: Achieved higher stability and better image quality than the standard GAN.
Conditional WGAN: Generated specific images conditioned on class labels.
Style Transfer: Artistic images using various styles like "Mosaic" and "Picasso" applied to content images.
Image-to-Image Transformer: Transformed one image into another with high fidelity.

PROJECT STRUCTURE:
```
/gan_models/             # GAN implementations
/style_transfer/         # Real-time style transfer implementation
/i2i_transformer/        # Image-to-image transformer implementation
/evaluation/             # Evaluation metrics and scripts (FID, IS)
/docs/                   # Documentation of experiments and results
requirements.txt         # Dependencies
README.md                # Project overview and instructions
```

FUTURE WORK:
Further optimization of real-time style transfer for better performance.
Exploring more advanced GAN variants for specific image generation tasks.
Improving image-to-image transformer models with attention mechanisms.

ACKNOWLEDGEMENTS:
I would like to express my gratitude to:
- Hikmat Farhat, my project supervisor, for his continued guidance and support.
- Danesh Tarapore, my second examiner, for his valuable feedback and insights.
- The University of Southampton's Electronics and Computer Science department for their resources and support.
